{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import PyTorch and BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version :  1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from IPython.display import clear_output\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-cased\"  \n",
    "\n",
    "# import the tokenizer which is used on this pretrained model\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "print(\"PyTorch version : \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data_place_of_death_unlabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this data\n",
      "Number of sentences :  5000\n",
      "Longest sentence's length : 1200\n",
      "Average length of the sentences : 128.044\n"
     ]
    }
   ],
   "source": [
    "print('For this data')\n",
    "print(\"Number of sentences : \", len(df))\n",
    "print(\"Longest sentence\\'s length : \" + str(df.sentence.map(len).max()))\n",
    "print(\"Average length of the sentences : \" + str(df.sentence.map(len).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit the tweet max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_text_length(text, length):\n",
    "    text = text[:length]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ludmila manicler born 6 july 1987 is an argent...</td>\n",
       "      <td>place of birth San Pedro</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she is a former member of the argentina women'...</td>\n",
       "      <td>place of birth San Pedro</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>li ge born 12 april 1969 is a chinese former g...</td>\n",
       "      <td>place of birth Zigong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kazuhiro \"daimajin\" sasaki 佐々木 主浩 sasaki kazuh...</td>\n",
       "      <td>place of birth Sendai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he played his entire npb career with the yokoh...</td>\n",
       "      <td>place of birth Sendai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>clemens fritz born 7 december 1980 is a german...</td>\n",
       "      <td>place of birth Erfurt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>he is mostly known for his 11-year spell at we...</td>\n",
       "      <td>place of birth Erfurt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>jim elmer larue august 11, 1925 – march 29, 20...</td>\n",
       "      <td>place of birth Clinton</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>he served as the head coach at the university ...</td>\n",
       "      <td>place of birth Clinton</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>cheng chin lung ; born 1 july 1998 in hong kon...</td>\n",
       "      <td>place of birth Hong Kong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     ludmila manicler born 6 july 1987 is an argent...   \n",
       "1     she is a former member of the argentina women'...   \n",
       "2     li ge born 12 april 1969 is a chinese former g...   \n",
       "3     kazuhiro \"daimajin\" sasaki 佐々木 主浩 sasaki kazuh...   \n",
       "4     he played his entire npb career with the yokoh...   \n",
       "...                                                 ...   \n",
       "4995  clemens fritz born 7 december 1980 is a german...   \n",
       "4996  he is mostly known for his 11-year spell at we...   \n",
       "4997  jim elmer larue august 11, 1925 – march 29, 20...   \n",
       "4998  he served as the head coach at the university ...   \n",
       "4999  cheng chin lung ; born 1 july 1998 in hong kon...   \n",
       "\n",
       "                      wikidata  label  \n",
       "0     place of birth San Pedro    NaN  \n",
       "1     place of birth San Pedro    NaN  \n",
       "2        place of birth Zigong    NaN  \n",
       "3        place of birth Sendai    NaN  \n",
       "4        place of birth Sendai    NaN  \n",
       "...                        ...    ...  \n",
       "4995     place of birth Erfurt    NaN  \n",
       "4996     place of birth Erfurt    NaN  \n",
       "4997    place of birth Clinton    NaN  \n",
       "4998    place of birth Clinton    NaN  \n",
       "4999  place of birth Hong Kong    NaN  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence'] = df['sentence'].map(lambda x: max_text_length(x, 1200))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WikiDataset(Dataset):\n",
    "    # read the tsv we make and initialize some parameters\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"validation\", \"test\"]\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(mode + \".csv\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer  # use BERT tokenizer\n",
    "    \n",
    "    # define a function that reutrn a training or testing data\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\" or self.mode == \"validation\":\n",
    "            sentence, wikidata = self.df.iloc[idx, :2].values\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            sentence, wikidata, label_id = self.df.iloc[idx, :].values\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "            \n",
    "        # BERT tokens\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_a = self.tokenizer.tokenize(sentence)\n",
    "        word_pieces += tokens_a + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "        \n",
    "        tokens_b = self.tokenizer.tokenize(wikidata)\n",
    "        word_pieces += tokens_b + [\"[SEP]\"]\n",
    "        len_b = len(word_pieces) - len_a\n",
    "        \n",
    "        # convert hole token sequence into index sequence\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # segments_tensor\n",
    "        segments_tensor = torch.tensor([0] * len_a + [1] * len_b, dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = WikiDataset(\"test\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a DataLoader that can return a mini-batch each time\n",
    "This DataLoader works with the 'WikiDataset' we define previously\n",
    "we need 4 tensors when training a BERT model：\n",
    "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
    "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
    "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
    "- label_ids       : (batch_size)\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# The input samples of this function is a list,\n",
    "# every element in it is a sample return by the 'WikiDataset'\n",
    "\n",
    "# Every sample contains 3 tensors : \n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "\n",
    "# It will procecss zero padding on the first two tensors,\n",
    "# then create a masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # with labels or not\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pading\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, batch_first=True)\n",
    "    \n",
    "    # attention masks, \n",
    "    # set the locations that are not zero padding tokens_tensors to 1 in order to let bert only focus on those tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(trainset, batch_size=128, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_place_of_birth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 2,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pruned_heads\": {},\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader):\n",
    "    predictions = None\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # first 3 tensors are tokens, segments and masks \n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            pred = logits.data\n",
    "                \n",
    "            # record current batch\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# run the model on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = get_predictions(model, testloader)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.7277, -2.7563],\n",
       "        [ 2.3453, -2.4456],\n",
       "        [ 2.8337, -2.7861],\n",
       "        ...,\n",
       "        [ 2.7025, -2.8294],\n",
       "        [ 1.7974, -2.5492],\n",
       "        [ 2.8001, -2.9380]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Softmax(dim=0)\n",
    "inconsistence_prob = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    value = m(preds[i])[1].cpu().numpy().tolist()\n",
    "    inconsistence_prob.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ludmila manicler born 6 july 1987 is an argent...</td>\n",
       "      <td>place of birth San Pedro</td>\n",
       "      <td>0.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she is a former member of the argentina women'...</td>\n",
       "      <td>place of birth San Pedro</td>\n",
       "      <td>0.008236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>li ge born 12 april 1969 is a chinese former g...</td>\n",
       "      <td>place of birth Zigong</td>\n",
       "      <td>0.003612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kazuhiro \"daimajin\" sasaki 佐々木 主浩 sasaki kazuh...</td>\n",
       "      <td>place of birth Sendai</td>\n",
       "      <td>0.003284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he played his entire npb career with the yokoh...</td>\n",
       "      <td>place of birth Sendai</td>\n",
       "      <td>0.008221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>clemens fritz born 7 december 1980 is a german...</td>\n",
       "      <td>place of birth Erfurt</td>\n",
       "      <td>0.005101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>he is mostly known for his 11-year spell at we...</td>\n",
       "      <td>place of birth Erfurt</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>jim elmer larue august 11, 1925 – march 29, 20...</td>\n",
       "      <td>place of birth Clinton</td>\n",
       "      <td>0.003943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>he served as the head coach at the university ...</td>\n",
       "      <td>place of birth Clinton</td>\n",
       "      <td>0.012785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>cheng chin lung ; born 1 july 1998 in hong kon...</td>\n",
       "      <td>place of birth Hong Kong</td>\n",
       "      <td>0.003211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     ludmila manicler born 6 july 1987 is an argent...   \n",
       "1     she is a former member of the argentina women'...   \n",
       "2     li ge born 12 april 1969 is a chinese former g...   \n",
       "3     kazuhiro \"daimajin\" sasaki 佐々木 主浩 sasaki kazuh...   \n",
       "4     he played his entire npb career with the yokoh...   \n",
       "...                                                 ...   \n",
       "4995  clemens fritz born 7 december 1980 is a german...   \n",
       "4996  he is mostly known for his 11-year spell at we...   \n",
       "4997  jim elmer larue august 11, 1925 – march 29, 20...   \n",
       "4998  he served as the head coach at the university ...   \n",
       "4999  cheng chin lung ; born 1 july 1998 in hong kon...   \n",
       "\n",
       "                      wikidata     label  \n",
       "0     place of birth San Pedro  0.004135  \n",
       "1     place of birth San Pedro  0.008236  \n",
       "2        place of birth Zigong  0.003612  \n",
       "3        place of birth Sendai  0.003284  \n",
       "4        place of birth Sendai  0.008221  \n",
       "...                        ...       ...  \n",
       "4995     place of birth Erfurt  0.005101  \n",
       "4996     place of birth Erfurt  0.002713  \n",
       "4997    place of birth Clinton  0.003943  \n",
       "4998    place of birth Clinton  0.012785  \n",
       "4999  place of birth Hong Kong  0.003211  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = inconsistence_prob\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['label'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she was the country's first female prime minister, attorney general, and leader of the opposition, pnm lose to peoples partnership in trinidad elections 2010]\n",
      "place of birth Penal\n",
      "0.993681788444519\n",
      "\n",
      "november 1879 mit seiner majestät alphons xii., könig von spanien, inhaber des infanterie-regiments nr\n",
      "place of birth Židlochovice\n",
      "0.977453887462616\n",
      "\n",
      "thumb|righteousness permits no turning back – hong kong art museum exhibit\n",
      "place of birth Shunde District\n",
      "0.9736953973770142\n",
      "\n",
      "he portrays jake sully in the avatar film series, marcus wright in terminator salvation, and perseus in clash of the titans as well as its sequel wrath of the titans\n",
      "place of birth Godalming\n",
      "0.9644454717636108\n",
      "\n",
      "in 2000 she was declared a saint by the catholic church\n",
      "place of birth Sultanate of Darfur\n",
      "0.962001383304596\n",
      "\n",
      "her first piece, a one-shot, was about old-style talking demons\n",
      "place of birth Kitakyūshū\n",
      "0.959858775138855\n",
      "\n",
      "he was an instrumental contributor to a number of major events in hungarian history, including passing and support of the april laws, the austro-hungarian compromise of 1867 and the hungarian nationalities law 1868.kozuchowski, adam\n",
      "place of birth Söjtör\n",
      "0.9536300897598267\n",
      "\n",
      "archduchess maria christina henriette desideria felicitas raineria of austria,\"maria christina henriette desideria felicitas raineria, sternkreuzordens-dame, ehrengroßkreuz des souveränen malteser-ritterordens; geb\n",
      "place of birth Židlochovice\n",
      "0.9536240100860596\n",
      "\n",
      "young terry bogard in fatal fury legend of the hungry wolf\n",
      "place of birth Sagamihara\n",
      "0.9515710473060608\n",
      "\n",
      "the bwf world tour are divided into six levels, namely world tour finals, super 1000, super 750, super 500, super 300 part of the hsbc world tour, and the bwf tour super 100\n",
      "place of birth Aichi Prefecture\n",
      "0.9478587508201599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(df.iloc[i]['sentence'])\n",
    "    print(df.iloc[i]['wikidata'])\n",
    "    print(df.iloc[i]['label'])\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
