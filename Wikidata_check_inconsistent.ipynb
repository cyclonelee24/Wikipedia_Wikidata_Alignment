{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import PyTorch and BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version :  1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from IPython.display import clear_output\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-cased\"  \n",
    "\n",
    "# import the tokenizer which is used on this pretrained model\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "print(\"PyTorch version : \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('./data/predicted_label_first_two_sentence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sid ahmed ghozali born 31 march 1937 in maghni...</td>\n",
       "      <td>place of birth ouedjda</td>\n",
       "      <td>0.993846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ahmed ben bella ; 25 december 1916 – 11 april ...</td>\n",
       "      <td>place of birth ouedjda</td>\n",
       "      <td>0.991789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ahmed ben bella was born in maghnia, in the fo...</td>\n",
       "      <td>place of birth ouedjda</td>\n",
       "      <td>0.991534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>born lourens alma tadema ; 8 january 1836 – 25...</td>\n",
       "      <td>place of birth Dronryp</td>\n",
       "      <td>0.989448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he was a member of the national liberation fro...</td>\n",
       "      <td>place of birth ouedjda</td>\n",
       "      <td>0.985167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159897</th>\n",
       "      <td>she is known as one of the members of the japa...</td>\n",
       "      <td>place of birth Hiroshima</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159898</th>\n",
       "      <td>and mabel née woodward johnson, in 1931 at aug...</td>\n",
       "      <td>place of birth Augusta</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159899</th>\n",
       "      <td>born in saint-étienne-de-lauzon, quebec, rober...</td>\n",
       "      <td>place of birth Lévis</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159900</th>\n",
       "      <td>265 bc – 241 bc, the elder son of eudamidas ii...</td>\n",
       "      <td>place of birth Sparta</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159901</th>\n",
       "      <td>william ii ; 25 february 1848 – 2 october 1921...</td>\n",
       "      <td>place of birth Stuttgart</td>\n",
       "      <td>0.000679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159902 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence  \\\n",
       "0       sid ahmed ghozali born 31 march 1937 in maghni...   \n",
       "1       ahmed ben bella ; 25 december 1916 – 11 april ...   \n",
       "2       ahmed ben bella was born in maghnia, in the fo...   \n",
       "3       born lourens alma tadema ; 8 january 1836 – 25...   \n",
       "4       he was a member of the national liberation fro...   \n",
       "...                                                   ...   \n",
       "159897  she is known as one of the members of the japa...   \n",
       "159898  and mabel née woodward johnson, in 1931 at aug...   \n",
       "159899  born in saint-étienne-de-lauzon, quebec, rober...   \n",
       "159900  265 bc – 241 bc, the elder son of eudamidas ii...   \n",
       "159901  william ii ; 25 february 1848 – 2 october 1921...   \n",
       "\n",
       "                        wikidata     label  \n",
       "0         place of birth ouedjda  0.993846  \n",
       "1         place of birth ouedjda  0.991789  \n",
       "2         place of birth ouedjda  0.991534  \n",
       "3         place of birth Dronryp  0.989448  \n",
       "4         place of birth ouedjda  0.985167  \n",
       "...                          ...       ...  \n",
       "159897  place of birth Hiroshima  0.000752  \n",
       "159898    place of birth Augusta  0.000695  \n",
       "159899      place of birth Lévis  0.000691  \n",
       "159900     place of birth Sparta  0.000689  \n",
       "159901  place of birth Stuttgart  0.000679  \n",
       "\n",
       "[159902 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['sentence', 'wikidata'])\n",
    "df_test = pd.DataFrame(columns=['sentence', 'wikidata', 'inconsistent_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iloc = [30, 39, 50, 52, 53]\n",
    "\n",
    "for ID in test_iloc:\n",
    "    test_sentence = df_2.iloc[ID]['sentence']\n",
    "    test_wikidata = df_2.iloc[ID]['wikidata']\n",
    "    test_prob = df_2.iloc[ID]['label']\n",
    "    new_row = {'sentence':test_sentence, 'wikidata':test_wikidata, 'inconsistent_prob':test_prob}\n",
    "    df_test = df_test.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>inconsistent_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>born and raised in morocco, he immigrated to t...</td>\n",
       "      <td>place of birth casablanca</td>\n",
       "      <td>0.850393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>born in casablanca, el adoua made his senior d...</td>\n",
       "      <td>place of birth casablanca</td>\n",
       "      <td>0.770453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was born on february 10, 1955 in casablanca, t...</td>\n",
       "      <td>place of birth casablanca</td>\n",
       "      <td>0.546604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>born in fenghuang, xiangxi prefecture of hunan...</td>\n",
       "      <td>place of birth fenghuang</td>\n",
       "      <td>0.515357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flynn was born in casablanca, morocco but grew...</td>\n",
       "      <td>place of birth casablanca</td>\n",
       "      <td>0.502653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  born and raised in morocco, he immigrated to t...   \n",
       "1  born in casablanca, el adoua made his senior d...   \n",
       "2  was born on february 10, 1955 in casablanca, t...   \n",
       "3  born in fenghuang, xiangxi prefecture of hunan...   \n",
       "4  flynn was born in casablanca, morocco but grew...   \n",
       "\n",
       "                    wikidata  inconsistent_prob  \n",
       "0  place of birth casablanca           0.850393  \n",
       "1  place of birth casablanca           0.770453  \n",
       "2  place of birth casablanca           0.546604  \n",
       "3   place of birth fenghuang           0.515357  \n",
       "4  place of birth casablanca           0.502653  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test)):\n",
    "    test_wikidata_list = df_test.iloc[i]['wikidata'].split(' ')\n",
    "    test_sentence = df_test.iloc[i]['sentence']\n",
    "    if 'casablanca' in test_wikidata_list:\n",
    "        test_wikidata_list.remove('casablanca')\n",
    "        test_wikidata_list.append('morocco')\n",
    "        new_row = {'sentence':test_sentence, 'wikidata':\" \".join(test_wikidata_list)}\n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "    else:\n",
    "        test_wikidata_list.remove('fenghuang')\n",
    "        test_wikidata_list.append('china')\n",
    "        new_row = {'sentence':test_sentence, 'wikidata':\" \".join(test_wikidata_list)}\n",
    "        df = df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentence_list = test_sentence.split(' ')\n",
    "# len_test_sentence = len(test_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len_test_sentence):\n",
    "#     test_sentence_list.remove(test_sentence_list[i])\n",
    "#     new_row = {'sentence':\" \".join(test_sentence_list), 'wikidata':test_wikidata}\n",
    "#     df = df.append(new_row, ignore_index=True)\n",
    "#     test_sentence_list = test_sentence.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>wikidata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>born and raised in morocco, he immigrated to t...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>born in casablanca, el adoua made his senior d...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was born on february 10, 1955 in casablanca, t...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>born in fenghuang, xiangxi prefecture of hunan...</td>\n",
       "      <td>place of birth china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flynn was born in casablanca, morocco but grew...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence                wikidata\n",
       "0  born and raised in morocco, he immigrated to t...  place of birth morocco\n",
       "1  born in casablanca, el adoua made his senior d...  place of birth morocco\n",
       "2  was born on february 10, 1955 in casablanca, t...  place of birth morocco\n",
       "3  born in fenghuang, xiangxi prefecture of hunan...    place of birth china\n",
       "4  flynn was born in casablanca, morocco but grew...  place of birth morocco"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WikiDataset(Dataset):\n",
    "    # read the tsv we make and initialize some parameters\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"validation\", \"test\"]\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv('./data/' + mode + \".csv\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer  # use BERT tokenizer\n",
    "    \n",
    "    # define a function that reutrn a training or testing data\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\" or self.mode == \"validation\":\n",
    "            sentence, wikidata = self.df.iloc[idx, :2].values\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            sentence, wikidata, label_id = self.df.iloc[idx, :].values\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "            \n",
    "        # BERT tokens\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_a = self.tokenizer.tokenize(sentence)\n",
    "        word_pieces += tokens_a + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "        \n",
    "        tokens_b = self.tokenizer.tokenize(wikidata)\n",
    "        word_pieces += tokens_b + [\"[SEP]\"]\n",
    "        len_b = len(word_pieces) - len_a\n",
    "        \n",
    "        # convert hole token sequence into index sequence\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # segments_tensor\n",
    "        segments_tensor = torch.tensor([0] * len_a + [1] * len_b, dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = WikiDataset(\"test\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# The input samples of this function is a list,\n",
    "# every element in it is a sample return by the 'WikiDataset'\n",
    "\n",
    "# Every sample contains 3 tensors : \n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "\n",
    "# It will procecss zero padding on the first two tensors,\n",
    "# then create a masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # with labels or not\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pading\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, batch_first=True)\n",
    "    \n",
    "    # attention masks, \n",
    "    # set the locations that are not zero padding tokens_tensors to 1 in order to let bert only focus on those tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(trainset, batch_size=128, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_place_of_birth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader):\n",
    "    predictions = None\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # first 3 tensors are tokens, segments and masks \n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            pred = logits.data\n",
    "                \n",
    "            # record current batch\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = get_predictions(model, testloader)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Softmax(dim=0)\n",
    "inconsistence_prob = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    value = m(preds[i])[1].cpu().numpy().tolist()\n",
    "    inconsistence_prob.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>inconsistent_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>born and raised in morocco, he immigrated to t...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "      <td>0.489572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>born in casablanca, el adoua made his senior d...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "      <td>0.989376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was born on february 10, 1955 in casablanca, t...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "      <td>0.478744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>born in fenghuang, xiangxi prefecture of hunan...</td>\n",
       "      <td>place of birth china</td>\n",
       "      <td>0.280171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flynn was born in casablanca, morocco but grew...</td>\n",
       "      <td>place of birth morocco</td>\n",
       "      <td>0.579261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence                wikidata  \\\n",
       "0  born and raised in morocco, he immigrated to t...  place of birth morocco   \n",
       "1  born in casablanca, el adoua made his senior d...  place of birth morocco   \n",
       "2  was born on february 10, 1955 in casablanca, t...  place of birth morocco   \n",
       "3  born in fenghuang, xiangxi prefecture of hunan...    place of birth china   \n",
       "4  flynn was born in casablanca, morocco but grew...  place of birth morocco   \n",
       "\n",
       "   inconsistent_prob  \n",
       "0           0.489572  \n",
       "1           0.989376  \n",
       "2           0.478744  \n",
       "3           0.280171  \n",
       "4           0.579261  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['inconsistent_prob'] = inconsistence_prob\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "born and raised in morocco, he immigrated to the united states with his family when he was 13\n",
      "place of birth casablanca\n",
      "0.8503934741020203\n",
      "-------------------------------\n",
      "born and raised in morocco, he immigrated to the united states with his family when he was 13\n",
      "place of birth morocco\n",
      "0.4895717203617096\n",
      "\n",
      "\n",
      "born in casablanca, el adoua made his senior debuts for his hometown's wydad casablanca, and formed a solid partnership with hicham louissi during his spell at the club\n",
      "place of birth casablanca\n",
      "0.7704533934593201\n",
      "-------------------------------\n",
      "born in casablanca, el adoua made his senior debuts for his hometown's wydad casablanca, and formed a solid partnership with hicham louissi during his spell at the club\n",
      "place of birth morocco\n",
      "0.9893761873245239\n",
      "\n",
      "\n",
      "was born on february 10, 1955 in casablanca, then part of french morocco\n",
      "place of birth casablanca\n",
      "0.5466042757034302\n",
      "-------------------------------\n",
      "was born on february 10, 1955 in casablanca, then part of french morocco\n",
      "place of birth morocco\n",
      "0.47874438762664795\n",
      "\n",
      "\n",
      "born in fenghuang, xiangxi prefecture of hunan, china, xiong was also a chinese scholar\n",
      "place of birth fenghuang\n",
      "0.5153570175170898\n",
      "-------------------------------\n",
      "born in fenghuang, xiangxi prefecture of hunan, china, xiong was also a chinese scholar\n",
      "place of birth china\n",
      "0.2801714241504669\n",
      "\n",
      "\n",
      "flynn was born in casablanca, morocco but grew up in jeffersonville, indiana, usa\n",
      "place of birth casablanca\n",
      "0.5026528239250183\n",
      "-------------------------------\n",
      "flynn was born in casablanca, morocco but grew up in jeffersonville, indiana, usa\n",
      "place of birth morocco\n",
      "0.5792614221572876\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_test)):\n",
    "    print(df_test.iloc[i]['sentence'])\n",
    "    print(df_test.iloc[i]['wikidata'])\n",
    "    print(df_test.iloc[i]['inconsistent_prob'])\n",
    "    print('-------------------------------')\n",
    "    print(df.iloc[i]['sentence'])\n",
    "    print(df.iloc[i]['wikidata'])\n",
    "    print(df.iloc[i]['inconsistent_prob'])\n",
    "    print('')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
